{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GitHub_TYMP_GlomProt_IHC_CNN_Fine-tuning_Xception_binary_V1.7_forGitHun.ipynb","provenance":[{"file_id":"1qm7LGf5f4HGQAU3wgGwsFiu0X9tamvSV","timestamp":1634912566260},{"file_id":"1UpN3uGxlm5iE639hx7isXY_41Edg4RkG","timestamp":1633545387546},{"file_id":"1E9EMaXcQgwXHvS-CgEEiAAPEPtnyHp5J","timestamp":1632382694531},{"file_id":"1tCFV0hqy06SKtBdYnDyoY9KotP-7caQ3","timestamp":1626275434011},{"file_id":"1k1JqgtfhAZ84jt8KlJ7IkMZZzjwFV3yj","timestamp":1624369667264},{"file_id":"1GqyffYpDdDlan-X3q0bvWNYi8ZHcbIBh","timestamp":1624363933567},{"file_id":"1usjQPhsO81BuqpPZu_-A0J2wUq3It9hP","timestamp":1624357169068},{"file_id":"1tSq480h1wX_ucG3IovAAlOfeeEbB1xQM","timestamp":1623782583616},{"file_id":"1ysAoKYZd2whivlNqe-nTHqwHj604gx6h","timestamp":1619722532895},{"file_id":"1I5WwP_dAjjSTLNxZdTG7hMTnZ1gq7Ur_","timestamp":1618757894016},{"file_id":"1UL1oJ_h7H4EUaK_wBKLBlWh4Rtd85tFY","timestamp":1618251946858},{"file_id":"1Ivr0x7UpOeF2piffz8LN4wBC7a42SqGU","timestamp":1617734643996},{"file_id":"1RQrz3I4C5GXieMOhBKGiied6Gg-805z0","timestamp":1617044233677},{"file_id":"1UzL9mBuF3hsz6ZsrssnBqWgRR7-5NUuU","timestamp":1617041335213},{"file_id":"1S9xznjjk2rdgF4mLTCT15Op1eYr62KGH","timestamp":1616440955347},{"file_id":"1P6JZqhxb-mYXJlscvRMFV0-z6sjkqwf0","timestamp":1616352388167},{"file_id":"1tUkJwMZ5O9F6VBr4NgH-0Se8xtWey5Fi","timestamp":1616067296810},{"file_id":"1s9pTYgURSbTPfggTZHFZV9z1xK91wSIF","timestamp":1616059377011},{"file_id":"1oWcKfGkcI8IaG_Jd1ejso0qHiwnJXuuF","timestamp":1615971857114},{"file_id":"1P-SWECRiMbcUg1CJulEtzYE5NKPFvM_u","timestamp":1615906668637},{"file_id":"1ZB3e-kbXwqu0k3kSfh0Dv1zMbhEgVwwN","timestamp":1615900766805}],"collapsed_sections":[],"mount_file_id":"1FDppvZv1QzjDNP5JRDNIeWudmhYhDL-0","authorship_tag":"ABX9TyPnWN46YGxO05ashxP23ZID"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6nr5dVc8ZvwT"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","import tensorflow as tf\n","import pandas as pd\n","import shutil\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.constraints import max_norm\n","from sklearn import metrics\n","from sklearn.utils import class_weight\n","from natsort import natsort_keygen\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.model_selection import train_test_split\n","from sklearn import model_selection\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import load_model\n","from sklearn.ensemble import RandomForestClassifier\n","from IPython.display import Image\n","import matplotlib.cm as cm\n","np.random.seed(42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pa4VoD_Z5pzA"},"source":["#it is assumed that all images of a given antibody is contained in a folder called '/.../Tiles' with two subfolders 'ABMR' and 'Other'\n","#creating the dataframe df3 containing all tile names, patient ID and corresponding group\n","#ABMR\n","filenames_ABMR = os.listdir('/.../Tiles/ABMR/')\n","filenames_ABMR = pd.DataFrame(filenames_ABMR, columns = ['tilesname'])\n","filenames_ABMR = filenames_ABMR.sort_values(by=\"tilesname\",key=natsort_keygen()).reset_index(drop=True)\n","df = filenames_ABMR.tilesname.str.extract('(?P<tilesname>.{9})')\n","df = df.rename(columns={\"tilesname\": \"patient\"})\n","df = pd.concat([df, filenames_ABMR], axis=1)\n","df.insert(0, 'group', 'ABMR')\n","#Other\n","filenames_other = os.listdir('/.../Tiles/Other/')\n","filenames_other = pd.DataFrame(filenames_other, columns = ['tilesname'])\n","filenames_other = filenames_other.sort_values(by=\"tilesname\",key=natsort_keygen()).reset_index(drop=True)\n","df2 = filenames_other.tilesname.str.extract('(?P<tilesname>.{9})')\n","df2 = df2.rename(columns={\"tilesname\": \"patient\"})\n","df2 = pd.concat([df2, filenames_other], axis=1)\n","df2.insert(0, 'group', 'Other')\n","#concatenate\n","df3 = pd.concat([df,df2])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEk_AyrxqRgl"},"source":["\n","#Creating one iteration of a 3-fold cross-validation (train/validation split)\n","groups_by_patient_id_list = np.array(df3['patient'].values)\n","y_labels = df3[\"group\"].values\n","\n","n_splits = 3\n","gkf = StratifiedGroupKFold(n_splits = 3,shuffle=True, random_state=42)  #change random_state here for computing other iterations\n","\n","result = []   \n","for train_idx, val_idx in gkf.split(df3, y_labels, groups = groups_by_patient_id_list):\n","    train_fold = df3.iloc[train_idx]\n","    val_fold = df3.iloc[val_idx]\n","    result.append((train_fold, val_fold))\n","    \n","train_fold_1, val_fold_1 = result[0][0],result[0][1]\n","train_fold_2, val_fold_2 = result[1][0],result[1][1]\n","train_fold_3, val_fold_3 = result[2][0],result[2][1]\n","\n","train_fold_1 = train_fold_1.reset_index(drop=True)\n","val_fold_1 = val_fold_1.reset_index(drop=True)\n","\n","train_fold_2 = train_fold_2.reset_index(drop=True)\n","val_fold_2 = val_fold_2.reset_index(drop=True)\n","\n","train_fold_3 = train_fold_3.reset_index(drop=True)\n","val_fold_3 = val_fold_3.reset_index(drop=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzgjFTITU7M4"},"source":["#List all file paths of the 3-fold cross validation respecting the train/validation split\n","def give_tiles_filepath(X_fold_X):    #X_fold_X: train/val(idation) and fold 1/2/3\n","    filepath = []\n","    for i in range(0,len(X_fold_X)):\n","      path = X_fold_X['group'].iloc[i] + '/' + X_fold_X['tilesname'].iloc[i]\n","      filepath.append(path)\n","    return filepath\n","\n","filepath_train_f1 = give_tiles_filepath(train_fold_1)\n","filepath_val_f1 = give_tiles_filepath(val_fold_1)\n","\n","filepath_train_f2 = give_tiles_filepath(train_fold_2)\n","filepath_val_f2 = give_tiles_filepath(val_fold_2)\n","\n","filepath_train_f3 = give_tiles_filepath(train_fold_3)\n","filepath_val_f3 = give_tiles_filepath(val_fold_3)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slIv0UPzigEs"},"source":["\n","source_folder = '/.../Tiles/'  #adapt here if needed\n","\n","def create_CV_directories(destination_folder,filepath_train,filepath_val):\n","    os.mkdir(destination_folder)\n","    os.mkdir(destination_folder + '/train')\n","    os.mkdir(destination_folder + '/train/ABMR')\n","    os.mkdir(destination_folder + '/train/Other')\n","\n","    os.mkdir(destination_folder + '/validation')\n","    os.mkdir(destination_folder + '/validation/ABMR')\n","    os.mkdir(destination_folder + '/validation/Other')\n","\n","    # copy/paste all selected files for the training dataset\n","    for file_name in filepath_train:\n","        # construct full file path\n","        source = source_folder + file_name\n","        destination = destination_folder + '/train/' + file_name\n","        # copy only files\n","        if os.path.isfile(source):\n","            shutil.copy(source, destination)\n","            print('copied', file_name)\n","\n","    # copy/paste all selected files for the validation dataset\n","    for file_name in filepath_val:\n","        # construct full file path\n","        source = source_folder + file_name\n","        destination = destination_folder + '/validation/' + file_name\n","        # copy only files\n","        if os.path.isfile(source):\n","            shutil.copy(source, destination)\n","            print('copied', file_name)\n","\n","#create 3 folders for each fold of the cross-validation respecting the train/validation split and ABMR/Other categories\n","create_CV_directories('/.../CV1',filepath_train_f1,filepath_val_f1)\n","create_CV_directories('/.../CV2',filepath_train_f2,filepath_val_f2)\n","create_CV_directories('/.../CV3',filepath_train_f3,filepath_val_f3)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JwJaSOlKiuHl"},"source":["#Train model 1 for one fold of the cross-validation\n","\n","#Select the fold\n","train_dir = '/.../CV1/train'  #adapt here for other folds\n","validation_dir = '/.../CV1/validation'  #adapt here for other folds\n","\n","#Some hyperparameters\n","batch_size = 64\n","img_height = 512\n","img_width = 512\n","\n","#Data augmentation for training and validation\n","#Training/validation with data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=180,\n","    width_shift_range=0.05,\n","    height_shift_range=0.05,\n","    brightness_range=None,\n","    shear_range=0.05,\n","    zoom_range=0.05,\n","    channel_shift_range=40,\n","    fill_mode=\"nearest\",\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    samplewise_center=True,\n","    rescale = 2/255.,\n",")\n","\n","#Without data augmentation\n","data = ImageDataGenerator(\n","    samplewise_center=True,\n","    rescale = 2/255.)\n","\n","#Creating image generator for training and validation images with data augmentation\n","train_generator = datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    color_mode=\"rgb\",\n","    classes=None,\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=42,\n","    interpolation=\"bicubic\",\n",")\n","\n","validation_generator = datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(img_height, img_width),\n","    color_mode=\"rgb\",\n","    classes=None,\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=42,\n","    interpolation=\"bicubic\",\n",")\n","\n","#Creating image generator for training and validation images without data augmentation (for input of model 2)\n","train_data = data.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    color_mode=\"rgb\",\n","    classes=None,\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    shuffle=False,\n","    interpolation=\"bicubic\",\n",")\n","\n","validation_data = data.flow_from_directory(\n","    validation_dir,\n","    target_size=(img_height, img_width),\n","    color_mode=\"rgb\",\n","    classes=None,\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    shuffle=False,\n","    interpolation=\"bicubic\",\n",")\n","#Dealing with potential imbalanced classes\n","class_weights = class_weight.compute_class_weight(\n","                class_weight='balanced',\n","                classes=np.unique(train_generator.classes), \n","                y=train_generator.classes)\n","class_weights = dict(enumerate(class_weights))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YhZLSgbmddPI"},"source":["#Functions to define\n","# Setup model for fine tuning\n","def setup_model(model, num_layer):\n","    #num_layer refers to the last layer to be freezed\n","    #Freeze the un-trainable layers of the model base\n","    for layer in model.layers[:num_layer]:\n","        layer.trainable = False\n","\n","    for layer in model.layers[num_layer:]:\n","        if not isinstance(layer, layers.BatchNormalization):\n","            layer.trainable = True\n","\n","    model.compile(\n","        loss='binary_crossentropy',\n","        optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","        metrics=keras.metrics.AUC(name='my_auc')\n","    )\n","\n","filepath = 'XXX/Saved_models/checkpoint.hdf5' #adapt here for model saving\n","\n","#define callbacks for saving best performing model on the validation set\n","callbacks_list = [\n","  keras.callbacks.ModelCheckpoint(\n","    filepath,\n","    monitor=\"val_my_auc\",\n","    verbose=1,\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode=\"max\",\n","    save_freq=\"epoch\",\n","    options=None,\n",")\n","]\n","\n","#Functions to define datasets for model 2 based on output of model 1\n","#function to create a dataframe including patient, tile names, predictions and corresponding group\n","def create_tablemaster(dataset, model):\n","    #Perform predictions (select image generator without data augmentation)\n","    predictions = model.predict(dataset, verbose=2)\n","\n","    filenames = dataset.filenames\n","    filenames_array = np.array(filenames)\n","    filenames_array = np.expand_dims(filenames_array, axis=1)\n","    results_array = np.hstack((filenames_array,predictions))\n","    results_df = pd.DataFrame(results_array, columns = ['tilesname','predictions'])\n","\n","    results_df[['group','tilesname']] = results_df.tilesname.str.split(\"/\",expand=True,)\n","    tablemaster = results_df.tilesname.str.extract('(?P<tilesname>.{9})')\n","    tablemaster = tablemaster.rename(columns={\"tilesname\": \"patient\"})\n","    tablemaster = pd.concat([tablemaster, results_df], axis=1)\n","    tablemaster[\"predictions\"] = pd.to_numeric(tablemaster.predictions, errors='coerce')\n","    tablemaster = tablemaster.sort_values(by=\"tilesname\",key=natsort_keygen())\n","    return tablemaster\n","\n","#function to define all variables for model 2 based on the output of model 1\n","def get_variables(tablemaster):\n","    #at tile level\n","    mean_patient = tablemaster.groupby('patient')[['predictions']].mean().reset_index()\n","    mean_patient = mean_patient.rename(columns={'predictions': 'mean'})\n","\n","    median_patient = tablemaster.groupby('patient')[['predictions']].median().reset_index()\n","    median_patient = median_patient.rename(columns={'predictions': 'median'})\n","\n","    min_patient = tablemaster.groupby('patient')[['predictions']].min().reset_index()\n","    min_patient = min_patient.rename(columns={'predictions': 'min'})\n","    \n","    max_patient = tablemaster.groupby('patient')[['predictions']].max().reset_index()\n","    max_patient = max_patient.rename(columns={'predictions': 'max'})\n","\n","    std_patient = tablemaster.groupby('patient')[['predictions']].std().reset_index()\n","    std_patient = std_patient.rename(columns={'predictions': 'std'})\n","    \n","    quantile75_patient = tablemaster.groupby('patient')[['predictions']].quantile(q=0.75).reset_index()\n","    quantile75_patient = quantile75_patient.rename(columns={'predictions': 'quantile75'})\n","    \n","    quantile25_patient = tablemaster.groupby('patient')[['predictions']].quantile(q=0.25).reset_index()\n","    quantile25_patient = quantile25_patient.rename(columns={'predictions': 'quantile25'})\n","\n","    #concatenate\n","    dataset = [mean_patient, median_patient, min_patient, max_patient, std_patient, quantile75_patient, quantile25_patient]\n","    dataset = pd.concat([df.set_index('patient') for df in dataset], axis=1, join='inner').reset_index()\n","    \n","    #Variables by average pooling\n","    tiles_value_list = tablemaster.groupby('patient')['predictions'].apply(list)\n","    data = []\n","    for i in range(0,len(tiles_value_list)):\n","    \n","        x = np.array(tiles_value_list[i])\n","        x = np.expand_dims(x, axis=(2, 0))\n","        avg_pool_1d = keras.layers.AveragePooling1D(pool_size=10,strides=5, padding='valid')\n","        y = avg_pool_1d(x)\n","        pool_quantile75 = np.quantile(y, 0.75)\n","        pool_quantile25 = np.quantile(y, 0.25)\n","        pool_minimum = np.amin(y)\n","        pool_maximum = np.amax(y)\n","        pool_std = np.std(y)\n","        data.append([pool_quantile75, pool_quantile25, pool_minimum, pool_maximum, pool_std])\n","    \n","    df_pooling = pd.DataFrame(data, columns=['pool_quantile75', 'pool_quantile25', 'pool_minimum', 'pool_maximum', 'pool_std'])\n","\n","    idx = tiles_value_list.index\n","    patient = idx.to_frame(index=False, name='patient')\n","\n","    df_pooling = pd.concat([patient, df_pooling], axis=1)\n","\n","    #concatenate\n","    dataset = pd.merge(dataset, df_pooling, on ='patient', how ='left')\n","    \n","    #adding corresponding group\n","    tablemaster_nodups = tablemaster.drop_duplicates(subset=('patient'))\n","    dataset = pd.merge(dataset, tablemaster_nodups[['patient','group']], on ='patient', how ='left')\n","    return dataset\n","    \n","#define numpy arrays from the previous datasets\n","def get_the_arrays(dataset):\n","    x_columns = dataset.columns.drop('patient').drop('group')\n","    x = dataset[x_columns].values\n","\n","    y = dataset['group'].map({'ABMR':1,\"Other\":0}).values # ABMR is 1 and Other is 0                                          \n","    y = np.expand_dims(y, axis=1)\n","    return x,y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f6s9VOYTb0Bp"},"source":["#Training of model 1\n","#loading ResNet50V2\n","base_model = keras.applications.ResNet50V2(\n","    weights='imagenet',  # Load weights pre-trained on ImageNet.\n","    input_shape=(img_height, img_width,3),  #define input shape\n","    include_top=False)  # Do not include the ImageNet classifier at the top. \n","base_model.trainable = False\n","\n","x = base_model.output\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n","model2 = keras.Model(base_model.input, outputs)\n","model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=keras.metrics.AUC(name='my_auc'))\n","\n","#Training for one epoch the added layers (convolutional blocks are kept frozen)\n","epochs=1\n","history2 = model2.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    verbose=1,\n","    callbacks=callbacks_list,\n","    class_weight=class_weights,\n",")\n","\n","# Setup model for fine tuning\n","setup_model(model2, 86)   # defreeze conv4 and conv5\n","#Fine tuning for 10 epochs\n","epochs=10\n","\n","history2 = model2.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    verbose=1,\n","    callbacks=callbacks_list,\n","    class_weight=class_weights,\n",")\n","\n","#visualization of performance during training\n","history_dict = history2.history\n","acc_values = history_dict['my_auc']\n","val_acc_values = history_dict['val_my_auc']\n","epochs = range(1, len(acc_values) + 1)\n","plt.plot(epochs, acc_values, 'bo', label='Training')\n","plt.plot(epochs, val_acc_values, 'b', label='Validation')\n","plt.title('AUC during training and validation')\n","plt.xlabel('Number of epochs')\n","plt.ylabel('AUC')\n","plt.legend()\n","plt.show()\n","plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxdqee9He6Im"},"source":["#Training of model 2\n","#load model (if needed)\n","save_path = '/XXX' #folder where models are saved\n","model = load_model(os.path.join(save_path,\"checkpoint.hdf5\"))\n","\n","#create dataframes (output from model 1)\n","train_tablemaster = create_tablemaster(train_data,model)\n","validation_tablemaster = create_tablemaster(validation_data,model)\n","\n","#creating arrays (input for model 2), training\n","train_set = get_variables(train_tablemaster)\n","x_train, y_train = get_the_arrays(train_set)\n","\n","#creating arrays (input for model 2), validaiton\n","test_set = get_variables(validation_tablemaster)\n","x_test, y_test = get_the_arrays(test_set)\n","\n","#training and evaluation of model 2 \n","y_train_rf = np.ravel(y_train)\n","\n","concatenated_auc = []\n","concatenated_Se_Y = []\n","concatenated_Sp_Y = []\n","concatenated_Se_C = []\n","concatenated_Sp_C = []\n","for i in range(0,50):  #averaging performances of 50 iterations\n","    #define and fit model\n","    rfc = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, class_weight=class_weights)\n","    rfc.fit(x_train,y_train_rf)\n","\n","    #auc score for each iteration\n","    rfc_predictions = rfc.predict_proba(x_test)\n","    auc_rfc = metrics.roc_auc_score(y_test, rfc_predictions[:,1])\n","    print(auc_rfc)\n","    #best Se and Sp\n","    fpr, tpr, thresholds = metrics.roc_curve(y_test, rfc_predictions[:,1])\n","    # Youden's statistic\n","    J = tpr - fpr\n","    ix = np.argmax(J)\n","    best_Se_Y = tpr[ix]\n","    best_Sp_Y = 1- fpr[ix]\n","    #closet topleft\n","    C = (1-tpr)**2 + (fpr)**2\n","    ix_C = np.argmin(C)\n","    best_Se_C = tpr[ix_C]\n","    best_Sp_C = 1 - fpr[ix_C]\n","\n","    #averaging scores\n","    concatenated_auc.append(auc_rfc)\n","    concatenated_Se_Y.append(best_Se_Y)\n","    concatenated_Sp_Y.append(best_Sp_Y)\n","    concatenated_Se_C.append(best_Se_C)\n","    concatenated_Sp_C.append(best_Sp_C)\n","\n","mean_auc = np.mean(concatenated_auc)\n","sample_std = np.std(concatenated_auc, ddof=1)\n","\n","print('mean_auc:',mean_auc, 'sample_std:',sample_std)\n","print('mean_Se_Y:',np.mean(concatenated_Se_Y), 'sample_std:',np.std(concatenated_Se_Y, ddof=1))\n","print('mean_Sp_Y:',np.mean(concatenated_Sp_Y), 'sample_std:',np.std(concatenated_Sp_Y, ddof=1))\n","print('mean_Se_C:',np.mean(concatenated_Se_C), 'sample_std:',np.std(concatenated_Se_C, ddof=1))\n","print('mean_Sp_C:',np.mean(concatenated_Sp_C), 'sample_std:',np.std(concatenated_Sp_C, ddof=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"XH8hESGZv5f-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GradCAM implementation (based on the keras documentation)\n","#training of Xception (data are exactly prepared as with ResNet50V2)\n","filepath = 'XXX/Saved_models/xceptionGradCAM.hdf5'  \n","\n","callbacks_list = [\n","  keras.callbacks.ModelCheckpoint(\n","    filepath,\n","    monitor=\"val_my_auc\",\n","    verbose=1,\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode=\"max\",\n","    save_freq=\"epoch\",\n","    options=None,\n",")\n","]\n","\n","base_model = keras.applications.Xception(\n","    weights='imagenet',  # Load weights pre-trained on ImageNet.\n","    input_shape=(img_height, img_width,3),\n","    include_top=False)  # Do not include the ImageNet classifier at the top. \n","base_model.trainable = False\n","\n","x = base_model.output\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n","model2 = keras.Model(base_model.input, outputs)\n","model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=keras.metrics.AUC(name='my_auc'))\n","\n","epochs=1\n","history2 = model2.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    verbose=1,\n","    callbacks=callbacks_list,\n","    class_weight=class_weights,\n",")\n","\n","# Setup model for fine tuning Xception\n","setup_model(model2, 116)   # defreeze conv4 et conv5\n","epochs=30\n","\n","history2 = model2.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    verbose=1,\n","    callbacks=callbacks_list,\n","    class_weight=class_weights,\n",")\n","\n","# Display\n","from IPython.display import Image\n","import matplotlib.cm as cm\n","\n","img_height = 512\n","img_width = 512\n","img_size = (img_height, img_width)\n","\n","#load model (if needed)\n","save_path = 'XXX/Saved_models' #put here the folder where models are saved\n","model = load_model(os.path.join(save_path,\"xceptionGradCAM.hdf5\"))\n","\n","last_conv_layer_name = \"block14_sepconv2_act\"\n","\n","classifier_layer_names = [\n","    \"global_average_pooling2d_1\",\n","    \"dense_1\",\n","]     #see model.summary() to match all layer names after last_conv_layer_name\n","\n","# The local path to our target image\n","img_path = 'XXX/ABMR/TYMP_S013_18_(13274.0,10199.0).jpg'  #path to an image\n","\n","display(Image(img_path))  #see the original tile image"],"metadata":{"id":"58peSaT7eQJd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#based on the implementation from keras, https://keras.io/examples/vision/grad_cam/\n","\n","def get_img_array(img_path, size):\n","    # `img` is a PIL image\n","    img = keras.preprocessing.image.load_img(img_path, target_size=size, color_mode=\"rgb\", interpolation=\"bicubic\")\n","    # `array` is a float32 Numpy array of shape (img_height, img_width, 3)\n","    array = keras.preprocessing.image.img_to_array(img)\n","    # We add a dimension to transform our array into a \"batch\"\n","    # of size (1, img_height, img_width, 3)\n","    array = np.expand_dims(array, axis=0)\n","    array /=127.5 \n","    array = array - array.mean()   #global centering\n","    return array\n","\n","def make_gradcam_heatmap(\n","    img_array, model, last_conv_layer_name, classifier_layer_names\n","):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer\n","    last_conv_layer = model.get_layer(last_conv_layer_name)\n","    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n","\n","    # Second, we create a model that maps the activations of the last conv\n","    # layer to the final class predictions\n","    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n","    x = classifier_input\n","    for layer_name in classifier_layer_names:\n","        x = model.get_layer(layer_name)(x)\n","    classifier_model = keras.Model(classifier_input, x)\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        # Compute activations of the last conv layer and make the tape watch it\n","        last_conv_layer_output = last_conv_layer_model(img_array)\n","        tape.watch(last_conv_layer_output)\n","        # Compute class predictions \n","        preds = classifier_model(last_conv_layer_output)\n","        if preds < 0.5:\n","          preds = 1 - preds\n","        top_class_channel = preds[:, tf.argmax(preds[0])]\n","\n","    # This is the gradient of the top predicted class with regard to\n","    # the output feature map of the last conv layer\n","    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n","    pooled_grads = pooled_grads.numpy()\n","    for i in range(pooled_grads.shape[-1]):\n","        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n","\n","    # The channel-wise mean of the resulting feature map\n","    # is our heatmap of class activation\n","    heatmap = np.mean(last_conv_layer_output, axis=-1)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n","    return heatmap"],"metadata":{"id":"GczupyFn3P0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Using GradCAM on one image tile\n","\n","img_path = 'XXX/TYMP_S013_18_(13274.0,10199.0).jpg'\n","\n","# Prepare image\n","img_array = get_img_array(img_path, size=img_size)\n","\n","# Define model\n","model = model  #or load model\n","\n","# Predict\n","preds = model.predict(img_array)\n","\n","# Generate class activation heatmap\n","heatmap = make_gradcam_heatmap(\n","    img_array, model, last_conv_layer_name, classifier_layer_names\n",")\n","\n","# Display heatmap\n","plt.matshow(heatmap)\n","plt.show()\n"],"metadata":{"id":"lh33Kf5XdWLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Superimposed images\n","# We load the original image\n","img = keras.preprocessing.image.load_img(img_path)\n","img = keras.preprocessing.image.img_to_array(img)\n","\n","# We rescale heatmap to a range 0-255\n","heatmap = np.uint8(255 * heatmap)\n","\n","# We use jet colormap to colorize heatmap\n","jet = cm.get_cmap(\"jet\")\n","\n","# We use RGB values of the colormap\n","jet_colors = jet(np.arange(256))[:, :3]\n","jet_heatmap = jet_colors[heatmap]\n","\n","# We create an image with RGB colorized heatmap\n","jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","\n","# Superimpose the heatmap on original image\n","superimposed_img = jet_heatmap * 0.4 + img\n","superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n","\n","# Display Grad CAM\n","#display(Image(save_path))\n","display(superimposed_img)\n","display(preds)"],"metadata":{"id":"ZV4uitiEvwgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"X0M06B2kvwm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"i8N-58Emvwua"},"execution_count":null,"outputs":[]}]}